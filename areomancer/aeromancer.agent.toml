# spec-ai Configuration (openai)
# Multi-model reasoning and knowledge graph are enabled by default

# Default agent with advanced features
default_agent = "aeromancer-default"

[database]
path = "./aeromancer.agent.db"

[model]
provider = "openai"
model_name = "gpt-4.1"
embeddings_model = "text-embedding-3-small"
# API key source (optional)
# Examples: "env:OPENAI_API_KEY", "file:~/.secrets/api_key"
# api_key_source = "env:OPENAI_API_KEY"

# Temperature for main model
temperature = 0.7

# UI configuration
[ui]
# Theme: "default", "dark", "light"
theme = "default"
# Prompt string
prompt = "specai (openai)> "

# Logging configuration
[logging]
# Log level: "trace", "debug", "info", "warn", "error"
level = "info"

# ========== DEFAULT AGENT WITH ALL FEATURES ==========
[agents.aeromancer-default]
# System prompt
prompt = """You are an autonomous assistant with advanced reasoning capabilities
derived from hierarchical multi-model reasoning developed using
a knowledge graph to track context and relationships."""

# Temperature for main model responses
temperature = 0.7

# Memory configuration
memory_k = 20  # Number of messages to recall
top_p = 0.9    # Top-p sampling for memory recall

# ========== KNOWLEDGE GRAPH (DEFAULT: ENABLED) ==========
enable_graph = true         # Build and use knowledge graph
graph_memory = true         # Use graph for memory recall
auto_graph = true          # Automatically extract entities and relationships
graph_steering = true      # Let graph influence decisions
graph_depth = 3           # Traversal depth for context
graph_weight = 0.5        # Balance between graph and semantic (0.0-1.0)
graph_threshold = 0.7     # Tool recommendation threshold

# ========== MULTI-MODEL REASONING (DEFAULT: ENABLED) ==========
fast_reasoning = true      # Use fast model for simple tasks

# Fast model configuration (Llama-3.2-3B)
fast_model_provider = "openai"  # Use LM Studio local server
fast_model_name = "gpt-4.1-mini"
fast_model_temperature = 0.3  # Lower for consistency

# For cross-platform (Ollama), uncomment:
# fast_model_provider = "ollama"
# fast_model_name = "llama3.2:3b"

# Tasks delegated to fast model for 10-15x speedup
fast_model_tasks = [
    "entity_extraction",      # Extract names, dates, URLs
    "graph_analysis",         # Analyze graph relationships
    "decision_routing",       # Determine task complexity
    "tool_selection",        # Choose appropriate tools
    "confidence_scoring",    # Assess response confidence
]

# Escalate to main model if confidence < 60%
escalation_threshold = 0.6

# Display reasoning summary to user (requires fast_reasoning = true)
# Shows a concise summary of the model's thought process
show_reasoning = false  # Default: false


[agents.simple]
# Simple agent without advanced features (backward compatibility)
prompt = "You are a helpful assistant."
temperature = 0.7
memory_k = 10

# Disable advanced features
enable_graph = false
fast_reasoning = false